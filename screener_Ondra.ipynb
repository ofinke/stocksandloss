{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "***\r\n",
    "# **Screener**\r\n",
    "\r\n",
    "Operation:\r\n",
    "1. Define function ```buysig()``` which scrapes stock data, calculates buy signals and returns pandas series holding information when the last buy signal happend and distance from today\r\n",
    "2. Filter results to show only buy signals from last two days\r\n",
    "3. Saves results into excel sheet"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# imports\r\n",
    "from scraper import stock_daily\r\n",
    "from IPython.display import display\r\n",
    "import datetime as dt\r\n",
    "import time\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import indicators as ind"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\r\n",
    "## **Define ```buysig()```**\r\n",
    "\r\n",
    "* Input: empty pandas series with predefined columns\r\n",
    "* Output: said series with filled results\r\n",
    "\r\n",
    "Scrapes data, calculate indicators and buy signals (depending on strategy, supports multiple strategies), saves results into series and outputs it. Currently supports following strategies:\r\n",
    "\r\n",
    "* SVF: Buy signal dependent on fast (5 days) and slow (21 days) stochastic oscillator and their crosses. Censored by trends in the VFI (uptrending histogram or VFI above 0)\r\n",
    "* S&F: Buy signals generated based on increasing momentum (calculated as a difference between EMA3-EMA10 and EMA3-EMA26). Censored by trends in the VFI\r\n",
    "* SMA bounces: Outputs stocks which bounced from SMA200 / SMA100 / SMA50 during last trading day. Stocks are required to be in general uptrend and bounced already."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def buysig(result):\r\n",
    "    # SCRAPING\r\n",
    "    try:\r\n",
    "        stock = stock_daily(result[\"ticker\"], save=False)\r\n",
    "    except:\r\n",
    "        print(result[\"ticker\"] + \": Exception occured during data scraping, skipped.\")\r\n",
    "        return result\r\n",
    "\r\n",
    "    # CREATING BUY SIGNALS\r\n",
    "    # Strategy SVF\r\n",
    "    # calculating indicators\r\n",
    "    vfi = ind.vfi(stock.data, period=30, coef=0.2, vcoef=1.5)\r\n",
    "    fs = ind.stoch(stock.data, period=5, sk=2, sd=3)\r\n",
    "    ss = ind.stoch(stock.data, period=21, sk=2, sd=5)\r\n",
    "    # calculating VFI histogram trend\r\n",
    "    window = 2\r\n",
    "    vfi_hist = vfi[\"histogram\"].rolling(window=window).apply(lambda x: np.polyfit(np.arange(window), x, 1)[0], raw=True).values\r\n",
    "    with np.errstate(invalid=\"ignore\"):\r\n",
    "        vfi_hist = vfi_hist > 0\r\n",
    "        # VFI trend\r\n",
    "        vfi_trend = vfi[\"vfi\"] > vfi[\"vfi_smooth\"]\r\n",
    "    vfi_conf = np.logical_or(vfi_hist, vfi_trend)\r\n",
    "    # calculating fast stochastic trend\r\n",
    "    window = 4\r\n",
    "    fs_conf = fs[\"k\"].rolling(window=window).apply(lambda x: np.polyfit(np.arange(window), x, 1)[0], raw=True).values\r\n",
    "    with np.errstate(invalid=\"ignore\"):\r\n",
    "        fs_conf = fs_conf > 0\r\n",
    "    # buy signals\r\n",
    "    conditions = np.logical_and((ss[\"k\"] > ss[\"d\"]).to_numpy(), (ss[\"d\"] >= 0).to_numpy())\r\n",
    "    bss = np.concatenate((np.array([0]), (conditions[:-1] < conditions[1:]))).astype(\"int\")\r\n",
    "    # finalize buy signals\r\n",
    "    svf = np.logical_and(np.logical_and(fs_conf, vfi_conf), bss)\r\n",
    "    # -------\r\n",
    "    # Strategy S&F Oscillator\r\n",
    "    ema3 = ind.ema(stock.data, 3, price=\"Typical\")[\"EMA\"].to_numpy()\r\n",
    "    ema10 = ind.ema(stock.data, 10, price=\"Open\")[\"EMA\"].to_numpy()\r\n",
    "    ema26 = ind.ema(stock.data, 26, price=\"Close\")[\"EMA\"].to_numpy()\r\n",
    "    # buy signal\r\n",
    "    bcurve = ema3-ema10\r\n",
    "    ccurve = ema3-ema26\r\n",
    "    lim = 0.1*stock.data[\"Close\"].to_numpy()\r\n",
    "    with np.errstate(invalid='ignore'):\r\n",
    "        bmask = bcurve > 0\r\n",
    "        cmask = (ccurve > -lim).astype(\"int\")\r\n",
    "    bsig = np.concatenate((np.array([0]), (bmask[:-1] < bmask[1:]))).astype(\"int\")\r\n",
    "    bsig = np.logical_and(bsig, cmask).astype(\"int\")\r\n",
    "    # VFI mask\r\n",
    "    vfimask = (vfi[\"vfi\"] > 0).to_numpy()\r\n",
    "    vfimask = np.logical_or(vfimask, (vfi[\"histogram\"] > 0).to_numpy())\r\n",
    "    saf = np.logical_and(bsig, vfimask).astype(\"int\")\r\n",
    "\r\n",
    "    # ------\r\n",
    "    # Strategy SMA bounce\r\n",
    "    # SMA200\r\n",
    "    sma200b = 0\r\n",
    "    try:\r\n",
    "        smaline = ind.sma(stock.data, 200, price=\"Close\")[\"SMA\"]\r\n",
    "        bounces = ind.sma_bounces(stock.data, smaline)\r\n",
    "        # we look at stock that are above the given SMA line for the past 100 days\r\n",
    "        dropsBelowSMA = np.where(stock.data[\"Close\"][-200:] - smaline[-200:] <0)[0]\r\n",
    "        # previous bounces from SMA, above SMA for 100 days and just above SMA the previous day\r\n",
    "        if bounces.size > 1 and dropsBelowSMA.size == 0 and (stock.data[\"Close\"].iat[-1]-smaline.iat[-1])/smaline.iloc[-1]<0.05: \r\n",
    "            sma200b = 1\r\n",
    "    except:\r\n",
    "        print(result[\"ticker\"] + \": problem during SMA200 bounce calculation\")\r\n",
    "    result[\"SMA200_bounce\"] = sma200b\r\n",
    "    # SMA100\r\n",
    "    sma100b = 0\r\n",
    "    try:\r\n",
    "        smaline = ind.sma(stock.data, 100, price=\"Close\")[\"SMA\"]\r\n",
    "        bounces = ind.sma_bounces(stock.data, smaline)\r\n",
    "        # we look at stock that are above the given SMA line for the past 100 days\r\n",
    "        dropsBelowSMA = np.where(stock.data[\"Close\"][-200:] - smaline[-200:] <0)[0]\r\n",
    "        # previous bounces from SMA, above SMA for 100 days and just above SMA the previous day\r\n",
    "        if bounces.size > 1 and dropsBelowSMA.size == 0 and (stock.data[\"Close\"].iat[-1]-smaline.iat[-1])/smaline.iloc[-1]<0.05: \r\n",
    "            sma100b = 1\r\n",
    "    except:\r\n",
    "        print(result[\"ticker\"] + \": problem during SMA100 bounce calculation\")\r\n",
    "    result[\"SMA100_bounce\"] = sma100b\r\n",
    "    # SMA50\r\n",
    "    sma50b = 0\r\n",
    "    try:\r\n",
    "        smaline = ind.sma(stock.data, 50, price=\"Close\")[\"SMA\"]\r\n",
    "        bounces = ind.sma_bounces(stock.data, smaline)\r\n",
    "        # we look at stock that are above the given SMA line for the past 100 days\r\n",
    "        dropsBelowSMA = np.where(stock.data[\"Close\"][-200:] - smaline[-200:] < 0)[0]\r\n",
    "        # previous bounces from SMA, above SMA for 100 days and just above SMA the previous day\r\n",
    "        if bounces.size > 1 and dropsBelowSMA.size == 0 and (stock.data[\"Close\"].iat[-1]-smaline.iat[-1])/smaline.iloc[-1]<0.05: \r\n",
    "            sma50b = 1\r\n",
    "    except:\r\n",
    "        print(result[\"ticker\"] + \": problem during SMA50 bounce calculation\")\r\n",
    "    result[\"SMA50_bounce\"] = sma50b\r\n",
    "    # SAVING DATA\r\n",
    "    # date of last buy signal and distance from today\r\n",
    "    # SVF\r\n",
    "    try:\r\n",
    "        lastindex = np.squeeze(np.where(svf == True))[-1]\r\n",
    "        result[\"buy_svf\"] = stock.data.loc[lastindex,\"Date\"]\r\n",
    "        result[\"dist_svf\"] = stock.data.index[-1] - lastindex\r\n",
    "    except:\r\n",
    "        print(result[\"ticker\"] + \": No SVF signals generated\")\r\n",
    "    # S&F\r\n",
    "    try:\r\n",
    "        lastindex = np.squeeze(np.where(saf == True))[-1]\r\n",
    "        result[\"buy_saf\"] = stock.data.loc[lastindex,\"Date\"]\r\n",
    "        result[\"dist_saf\"] = stock.data.index[-1] - lastindex\r\n",
    "    except:\r\n",
    "        print(result[\"ticker\"] + \": No S&F signals generated\")\r\n",
    "\r\n",
    "    return result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\r\n",
    "## **Run the analysis**\r\n",
    "\r\n",
    "Tickers are stored in ```tickers.xlsx``` excel file where multiple sheets are defined. By modifying the *sheets* variable, one can choose which stocks to scan through\r\n",
    "\r\n",
    "Sheets in the excel:\r\n",
    "1. spy - holds all stock tickers present in the SPY ETF\r\n",
    "2. iwm - holds top 600 holdings in the IWM ETF which follows Russell 2000\r\n",
    "3. watchlist - list of stocks I'm personally interested in and found somewhere else, on fintwit, reddit, my own research\r\n",
    "4. longs - stocks I have high conviction in and want to hold long term\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# which sheets to use:\r\n",
    "# sheets = [\"spy\", \"iwm\", \"watchlist\", \"longs\", \"midcap\", \"largecap\"] # specific scan\r\n",
    "sheets = [\"filtered\"] # full nasdaq, filtered by volume and volatility\r\n",
    "# sheets = [\"test\"]\r\n",
    "\r\n",
    "# read tickers from excel file\r\n",
    "excel = pd.read_excel(\"tickers.xlsx\", sheet_name=sheets)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# define empty dataframe\r\n",
    "data = pd.DataFrame(columns=[\"ticker\", \"type\", \"buy_svf\", \"dist_svf\", \"buy_saf\", \"dist_saf\", \"SMA50_bounce\", \"SMA100_bounce\", \"SMA200_bounce\"])\r\n",
    "# run analysis\r\n",
    "for i in sheets:\r\n",
    "    for j in excel[i][\"ticker\"].to_list():\r\n",
    "        # define series\r\n",
    "        ser = {\"ticker\": j, \"type\": i, \"buy_svf\": np.nan, \"dist_svf\": np.nan, \"buy_saf\": np.nan, \"dist_saf\": np.nan, \"SMA50_bounce\": np.nan, \"SMA100_bounce\": np.nan, \"SMA200_bounce\": np.nan}\r\n",
    "        ser = pd.Series(data=ser)\r\n",
    "        # delay for better scrapping (without this, scraping sometimes returns incorrect answers)\r\n",
    "        time.sleep(1)\r\n",
    "        # calculation\r\n",
    "        res = buysig(ser).to_frame().T\r\n",
    "        data = data.append(res, ignore_index=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "ABOS: No SVF signals generated\n",
      "ABOS: No S&F signals generated\n",
      "ABSI: No SVF signals generated\n",
      "ABSI: No S&F signals generated\n",
      "ADGI: No SVF signals generated\n",
      "ADGI: No S&F signals generated\n",
      "AGRI: No SVF signals generated\n",
      "AGRI: No S&F signals generated\n",
      "ALKT: No S&F signals generated\n",
      "ALZN: No SVF signals generated\n",
      "ALZN: No S&F signals generated\n",
      "ATAI: No SVF signals generated\n",
      "ATAI: No S&F signals generated\n",
      "AVAH: No S&F signals generated\n",
      "BASE: No SVF signals generated\n",
      "BASE: No S&F signals generated\n",
      "BHG: No SVF signals generated\n",
      "BHG: No S&F signals generated\n",
      "BLND: No SVF signals generated\n",
      "BLND: No S&F signals generated\n",
      "BON: No SVF signals generated\n",
      "BON: No S&F signals generated\n",
      "CADL: No SVF signals generated\n",
      "CADL: No S&F signals generated\n",
      "CFLT: No SVF signals generated\n",
      "CLVR: No S&F signals generated\n",
      "CNM: No SVF signals generated\n",
      "CNM: No S&F signals generated\n",
      "CNTA: No SVF signals generated\n",
      "CNTA: No S&F signals generated\n",
      "CNVY: No S&F signals generated\n",
      "COOK: No SVF signals generated\n",
      "COOK: No S&F signals generated\n",
      "CPOP: No SVF signals generated\n",
      "CPOP: No S&F signals generated\n",
      "CRBU: No SVF signals generated\n",
      "CRBU: No S&F signals generated\n",
      "CURV: No SVF signals generated\n",
      "CURV: No S&F signals generated\n",
      "CVRX: No SVF signals generated\n",
      "CVRX: No S&F signals generated\n",
      "CXM: No SVF signals generated\n",
      "CXM: No S&F signals generated\n",
      "CYT: No SVF signals generated\n",
      "CYT: No S&F signals generated\n",
      "DATS: No SVF signals generated\n",
      "DATS: No S&F signals generated\n",
      "DBGI: No SVF signals generated\n",
      "DBGI: No S&F signals generated\n",
      "DIBS: No SVF signals generated\n",
      "DIBS: No S&F signals generated\n",
      "DNAY: No S&F signals generated\n",
      "DOCS: No SVF signals generated\n",
      "DOCS: No S&F signals generated\n",
      "DUOL: No SVF signals generated\n",
      "DUOL: No S&F signals generated\n",
      "EJH: No S&F signals generated\n",
      "EVCM: No SVF signals generated\n",
      "EVCM: No S&F signals generated\n",
      "EWCZ: No SVF signals generated\n",
      "EWCZ: No S&F signals generated\n",
      "FCUV: No SVF signals generated\n",
      "FCUV: No S&F signals generated\n",
      "FIGS: No SVF signals generated\n",
      "FIGS: No S&F signals generated\n",
      "FLGC: No S&F signals generated\n",
      "FTCI: No S&F signals generated\n",
      "FXLV: No SVF signals generated\n",
      "FXLV: No S&F signals generated\n",
      "GHRS: No SVF signals generated\n",
      "GMVD: No SVF signals generated\n",
      "GMVD: No S&F signals generated\n",
      "GRAY: No S&F signals generated\n",
      "GRPH: No SVF signals generated\n",
      "GRPH: No S&F signals generated\n",
      "GRVI: No SVF signals generated\n",
      "GRVI: No S&F signals generated\n",
      "HEPS: No SVF signals generated\n",
      "HEPS: No S&F signals generated\n",
      "HOOD: No SVF signals generated\n",
      "HOOD: No S&F signals generated\n",
      "IINN: No SVF signals generated\n",
      "IINN: No S&F signals generated\n",
      "IMGO: No SVF signals generated\n",
      "IMGO: No S&F signals generated\n",
      "INST: No SVF signals generated\n",
      "INST: No S&F signals generated\n",
      "INTA: No SVF signals generated\n",
      "INTA: No S&F signals generated\n",
      "IPSC: No SVF signals generated\n",
      "IPSC: No S&F signals generated\n",
      "IPW: No SVF signals generated\n",
      "ISPC: No SVF signals generated\n",
      "ISPC: No S&F signals generated\n",
      "JZXN: No S&F signals generated\n",
      "LDI: No S&F signals generated\n",
      "LFST: No S&F signals generated\n",
      "LVTX: No S&F signals generated\n",
      "LYEL: No S&F signals generated\n",
      "LZ: No SVF signals generated\n",
      "LZ: No S&F signals generated\n",
      "MCG: No SVF signals generated\n",
      "MCG: No S&F signals generated\n",
      "MCW: No S&F signals generated\n",
      "MILE: No S&F signals generated\n",
      "MLNK: No SVF signals generated\n",
      "MLNK: No S&F signals generated\n",
      "MMMB: No SVF signals generated\n",
      "MMMB: No S&F signals generated\n",
      "MQ: No SVF signals generated\n",
      "MQ: No S&F signals generated\n",
      "MXCT: No SVF signals generated\n",
      "MXCT: No S&F signals generated\n",
      "NABL: No SVF signals generated\n",
      "NABL: No S&F signals generated\n",
      "OB: No SVF signals generated\n",
      "OB: No S&F signals generated\n",
      "OG: No S&F signals generated\n",
      "OGN: No S&F signals generated\n",
      "OMGA: No SVF signals generated\n",
      "OMGA: No S&F signals generated\n",
      "OMIC: No SVF signals generated\n",
      "OMIC: No S&F signals generated\n",
      "OSCR: No S&F signals generated\n",
      "PWSC: No SVF signals generated\n",
      "PWSC: No S&F signals generated\n",
      "PYCR: No SVF signals generated\n",
      "PYCR: No S&F signals generated\n",
      "RERE: No SVF signals generated\n",
      "RERE: No S&F signals generated\n",
      "RSKD: No SVF signals generated\n",
      "RSKD: No S&F signals generated\n",
      "RXST: No SVF signals generated\n",
      "RXST: No S&F signals generated\n",
      "RYAN: No SVF signals generated\n",
      "RYAN: No S&F signals generated\n",
      "S: No SVF signals generated\n",
      "S: No S&F signals generated\n",
      "SANA: No S&F signals generated\n",
      "SNTG: No SVF signals generated\n",
      "SNTG: No S&F signals generated\n",
      "SOPH: No SVF signals generated\n",
      "SOPH: No S&F signals generated\n",
      "STVN: No SVF signals generated\n",
      "STVN: No S&F signals generated\n",
      "SWIM: No S&F signals generated\n",
      "TMCI: No S&F signals generated\n",
      "TNYA: No SVF signals generated\n",
      "TNYA: No S&F signals generated\n",
      "TRMR: No SVF signals generated\n",
      "TRMR: No S&F signals generated\n",
      "TSP: No S&F signals generated\n",
      "UNCY: No SVF signals generated\n",
      "UNCY: No S&F signals generated\n",
      "USWS: No S&F signals generated\n",
      "VERV: No S&F signals generated\n",
      "VMEO: No S&F signals generated\n",
      "VRAR: No SVF signals generated\n",
      "VRAR: No S&F signals generated\n",
      "VSCO: No SVF signals generated\n",
      "VSCO: No S&F signals generated\n",
      "VTEX: No SVF signals generated\n",
      "VTEX: No S&F signals generated\n",
      "WAVE: No SVF signals generated\n",
      "WAVE: No S&F signals generated\n",
      "WDH: No S&F signals generated\n",
      "WEBR: No SVF signals generated\n",
      "WEBR: No S&F signals generated\n",
      "WKME: No S&F signals generated\n",
      "XMTR: No SVF signals generated\n",
      "XMTR: No S&F signals generated\n",
      "XPOF: No SVF signals generated\n",
      "XPOF: No S&F signals generated\n",
      "YMM: No SVF signals generated\n",
      "YOU: No SVF signals generated\n",
      "YOU: No S&F signals generated\n",
      "YQ: No S&F signals generated\n",
      "ZETA: No SVF signals generated\n",
      "ZETA: No S&F signals generated\n",
      "ZME: No S&F signals generated\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***\r\n",
    "## Print & Save results"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# display results\r\n",
    "display(data[(data[\"dist_svf\"] < 1) | (data[\"dist_saf\"] < 1)].drop_duplicates(subset=\"ticker\").reset_index(drop=True))\r\n",
    "# save data\r\n",
    "data[(data[\"dist_svf\"] <= 1) | (data[\"dist_saf\"] <= 1)].drop_duplicates(subset=\"ticker\").reset_index(drop=True).to_excel(\"Screener-\"+str(dt.date.today())+\".xlsx\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>type</th>\n",
       "      <th>buy_svf</th>\n",
       "      <th>dist_svf</th>\n",
       "      <th>buy_saf</th>\n",
       "      <th>dist_saf</th>\n",
       "      <th>SMA50_bounce</th>\n",
       "      <th>SMA100_bounce</th>\n",
       "      <th>SMA200_bounce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACB</td>\n",
       "      <td>filtered</td>\n",
       "      <td>2021-10-14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-28 00:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACER</td>\n",
       "      <td>filtered</td>\n",
       "      <td>2021-10-14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-06 00:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADCT</td>\n",
       "      <td>filtered</td>\n",
       "      <td>2021-08-25 00:00:00</td>\n",
       "      <td>35</td>\n",
       "      <td>2021-10-14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADES</td>\n",
       "      <td>filtered</td>\n",
       "      <td>2021-09-14 00:00:00</td>\n",
       "      <td>22</td>\n",
       "      <td>2021-10-14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADIL</td>\n",
       "      <td>filtered</td>\n",
       "      <td>2021-10-13 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-10-14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>XELB</td>\n",
       "      <td>filtered</td>\n",
       "      <td>2021-10-14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-08-31 00:00:00</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>YETI</td>\n",
       "      <td>filtered</td>\n",
       "      <td>2021-10-14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-10-14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>ZOM</td>\n",
       "      <td>filtered</td>\n",
       "      <td>2021-10-14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-30 00:00:00</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>KBH</td>\n",
       "      <td>filtered</td>\n",
       "      <td>2021-10-05 00:00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2021-10-14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>SPIR</td>\n",
       "      <td>filtered</td>\n",
       "      <td>2021-10-14 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-09-16 00:00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ticker      type              buy_svf dist_svf              buy_saf  \\\n",
       "0      ACB  filtered  2021-10-14 00:00:00        0  2021-09-28 00:00:00   \n",
       "1     ACER  filtered  2021-10-14 00:00:00        0  2021-10-06 00:00:00   \n",
       "2     ADCT  filtered  2021-08-25 00:00:00       35  2021-10-14 00:00:00   \n",
       "3     ADES  filtered  2021-09-14 00:00:00       22  2021-10-14 00:00:00   \n",
       "4     ADIL  filtered  2021-10-13 00:00:00        1  2021-10-14 00:00:00   \n",
       "..     ...       ...                  ...      ...                  ...   \n",
       "230   XELB  filtered  2021-10-14 00:00:00        0  2021-08-31 00:00:00   \n",
       "231   YETI  filtered  2021-10-14 00:00:00        0  2021-10-14 00:00:00   \n",
       "232    ZOM  filtered  2021-10-14 00:00:00        0  2021-09-30 00:00:00   \n",
       "233    KBH  filtered  2021-10-05 00:00:00        7  2021-10-14 00:00:00   \n",
       "234   SPIR  filtered  2021-10-14 00:00:00        0  2021-09-16 00:00:00   \n",
       "\n",
       "    dist_saf SMA50_bounce SMA100_bounce SMA200_bounce  \n",
       "0         12            0             0             0  \n",
       "1          6            0             0             0  \n",
       "2          0            0             0             0  \n",
       "3          0            0             0             0  \n",
       "4          0            0             0             0  \n",
       "..       ...          ...           ...           ...  \n",
       "230       31            0             0             0  \n",
       "231        0            0             0             0  \n",
       "232       10            0             0             0  \n",
       "233        0            0             0             0  \n",
       "234       20            0             0             0  \n",
       "\n",
       "[235 rows x 9 columns]"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}